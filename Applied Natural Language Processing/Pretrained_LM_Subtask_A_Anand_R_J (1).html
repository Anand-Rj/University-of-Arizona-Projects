<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>8bff7ab07fec4bd591d31f742d79cc9c</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="pre-trained-language-models-subtask-a"
class="cell markdown" data-deletable="false" data-editable="false"
id="DlMUXan0sGcG">
<h1>Pre-trained Language Models: SubTask A.</h1>
<h2 id="6-marks">[6 Marks]</h2>
<p>In this assignment, you will work on the <a
href="https://competitions.codalab.org/competitions/21080">ComVE</a>
shared task that was part of SemEval-2020. The task aims to evaluate
whether a system can distinguish if a natural language statement makes
sense to humans or not and provide a reason. <strong>ConVE</strong>
includes three subtasks that require models to acquire and apply
commonsense knowledge. In this notebook you will focus on
<strong>SubTask A</strong>:</p>
<ul>
<li><p>Given two similar statements that differ by only a few words,
select the statement of the two that does not make sense. For example,
within the statements below, <em>Statement 2</em> is the nonsensical
statement:</p>
<p><em>Statement 1</em>: He put a turkey into the fridge.<br />
<em>Statement 2</em>: He put an elephant into the fridge.</p>
<p>This subtask can be approached as a Text Matching problem where the
input is the two statements and the output is a label indicating which
is the nonsensical one.</p></li>
</ul>
<p>You will fine-tune a Pre-trained Language Model with <a
href="https://huggingface.co/docs/transformers/index">Transformers</a>
library that provides a set of tools for fine-tunning and deploying a
wide variety of Pre-trained Language Models. The <a
href="https://huggingface.co/models">Hugging Face Hub</a> allows you to
explore all the models supported by <strong>Transformers</strong> and
even share your own models with the community. In this assignment, you
will work with <a
href="https://huggingface.co/docs/transformers/model_doc/roberta">RoBERTa</a>,
a model that uses <strong>BERT</strong>'s architecture but has been
pre-trained with more data and a more carefully selected set of
hyperparameters.</p>
<p>Fine-tuning a Pre-trained Language Model usually requires a great
amount of time and computational resources. Your personal computer will
not be probably enough. In order to complete the assignment, you can
work with a reduced version of the dataset and the base version of
<strong>RoBERTa</strong>:</p>
</section>
<div class="cell code" data-execution_count="1"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ZntqfPj-V_RJ" data-outputId="5cdea347-2e4f-4ff1-8959-55fa2ac6abeb">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>pip install <span class="op">--</span>upgrade nbconvert</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (7.16.4)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (4.12.3)
Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (6.1.0)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.7.1)
Requirement already satisfied: jinja2&gt;=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.1.4)
Requirement already satisfied: jupyter-core&gt;=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.7.2)
Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.3.0)
Requirement already satisfied: markupsafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (2.1.5)
Requirement already satisfied: mistune&lt;4,&gt;=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (3.0.2)
Requirement already satisfied: nbclient&gt;=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (0.10.0)
Requirement already satisfied: nbformat&gt;=5.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.10.4)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert) (24.1)
Requirement already satisfied: pandocfilters&gt;=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (1.5.1)
Requirement already satisfied: pygments&gt;=2.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (2.16.1)
Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (1.3.0)
Requirement already satisfied: traitlets&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert) (5.7.1)
Requirement already satisfied: six&gt;=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0-&gt;nbconvert) (1.16.0)
Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0-&gt;nbconvert) (0.5.1)
Requirement already satisfied: platformdirs&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core&gt;=4.7-&gt;nbconvert) (4.2.2)
Requirement already satisfied: jupyter-client&gt;=6.1.12 in /usr/local/lib/python3.10/dist-packages (from nbclient&gt;=0.5.0-&gt;nbconvert) (6.1.12)
Requirement already satisfied: fastjsonschema&gt;=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat&gt;=5.7-&gt;nbconvert) (2.20.0)
Requirement already satisfied: jsonschema&gt;=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat&gt;=5.7-&gt;nbconvert) (4.19.2)
Requirement already satisfied: soupsieve&gt;1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-&gt;nbconvert) (2.5)
Requirement already satisfied: attrs&gt;=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=5.7-&gt;nbconvert) (23.2.0)
Requirement already satisfied: jsonschema-specifications&gt;=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=5.7-&gt;nbconvert) (2023.12.1)
Requirement already satisfied: referencing&gt;=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=5.7-&gt;nbconvert) (0.35.1)
Requirement already satisfied: rpds-py&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema&gt;=2.6-&gt;nbformat&gt;=5.7-&gt;nbconvert) (0.18.1)
Requirement already satisfied: pyzmq&gt;=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client&gt;=6.1.12-&gt;nbclient&gt;=0.5.0-&gt;nbconvert) (24.0.1)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client&gt;=6.1.12-&gt;nbclient&gt;=0.5.0-&gt;nbconvert) (2.8.2)
Requirement already satisfied: tornado&gt;=4.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client&gt;=6.1.12-&gt;nbclient&gt;=0.5.0-&gt;nbconvert) (6.3.3)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="2" id="H7W_ZVJUsGcK">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>shrink_dataset <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>colab <span class="op">=</span> <span class="va">False</span></span></code></pre></div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="10U6D0JXsGcL">
<p>Although the value of these variables do not affect the tests that
will evaluate your code, the output examples distributed throughout this
notebook are based on a <code>shrink_dataset</code> and a
<code>base_model</code> variables set as <code>True</code>, and a
<code>colab</code> variable set as <code>False</code>.</p>
<p>If you want to perform a full training of the model to obtain its
real performance, you can use a cloud service like <a
href="https://colab.research.google.com/">Google Colab</a>.
<strong>Colab</strong> is a <strong>Jupyter</strong> notebook
environment that supports both GPU and TPU instances, allowing training
large scale Deep Learning models. Set the <code>shrink_dataset</code>
and a <code>base_model</code> variables to <code>False</code>, the
<code>colab</code> variable to <code>True</code>, and follow the
instructions provided to you to run the notebook in
<strong>Colab</strong>.</p>
</div>
<div class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="IWka5_suWxHM" data-outputId="f8c187bd-2c57-42db-a533-5be706b41185">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install evaluate</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)
Requirement already satisfied: datasets&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.20.0)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)
Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)
Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)
Requirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)
Requirement already satisfied: tqdm&gt;=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)
Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)
Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)
Requirement already satisfied: fsspec[http]&gt;=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)
Requirement already satisfied: huggingface-hub&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.4)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate) (3.15.4)
Requirement already satisfied: pyarrow&gt;=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate) (16.1.0)
Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate) (0.6)
Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate) (3.9.5)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets&gt;=2.0.0-&gt;evaluate) (6.0.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.7.0-&gt;evaluate) (4.12.2)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;evaluate) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;evaluate) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;evaluate) (2.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;evaluate) (2024.6.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;evaluate) (2.8.2)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;evaluate) (2023.4)
Requirement already satisfied: tzdata&gt;=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;evaluate) (2024.1)
Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate) (1.3.1)
Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate) (23.2.0)
Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate) (1.4.1)
Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate) (6.0.5)
Requirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate) (1.9.4)
Requirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets&gt;=2.0.0-&gt;evaluate) (4.0.3)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;evaluate) (1.16.0)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="4" data-deletable="false"
data-editable="false" id="cmp-5QxbsGcL">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> colab:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span> pip install transformers datasets evaluate</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> os</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> os.path.exists(<span class="st">&quot;SemEval2020-Task4-Data/ALL data/Training  Data/subtaskA_data_all.csv&quot;</span>):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="op">!</span> git clone https:<span class="op">//</span>github.com<span class="op">/</span>wangcunxiang<span class="op">/</span>SemEval2020<span class="op">-</span>Task4<span class="op">-</span>Commonsense<span class="op">-</span>Validation<span class="op">-</span><span class="kw">and</span><span class="op">-</span>Explanation.git SemEval2020<span class="op">-</span>Task4<span class="op">-</span>Data</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="JKFF3RlibV5i" data-outputId="edf29328-1a5e-4b74-f896-b499f743b710">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">&#39;/content/drive&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True).
</code></pre>
</div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="UGH1LMqnsGcM">
<p>You will use the following objects and functions:</p>
</div>
<div class="cell code" data-execution_count="6" data-deletable="false"
data-editable="false" id="K23Q0_2hsGcM">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> evaluate</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> Dataset</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> (AutoTokenizer, AutoModelForSequenceClassification,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                          TrainingArguments, Trainer,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                          enable_full_determinism)</span></code></pre></div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="RYdSkPDHsGcN">
<p>When working with Neural Networks, there are a large number of random
operations such as initializing the weights of the network, shuffling
the data for training, or choosing samples. This causes that different
training runs of the same model can lead to different results. To ensure
reproducibility, i.e. obtaining the same results in the different runs,
the random number generator must be initialized with a fixed value known
as seed. In <strong>Transformers</strong>, this can be done as
follows:</p>
</div>
<div class="cell code" data-execution_count="7" data-deletable="false"
data-editable="false" id="M8NxKFntsGcN">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>enable_full_determinism(seed<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="YbgU0WTPsGcO">
<blockquote>
<p><strong>Note!</strong> With models as complex as Neural Networks,
reproducibility is susceptible to factors such as software versions or
the hardware on which the models are run. Even with seed initialization,
there may be slight differences in the results.</p>
</blockquote>
<p>Working with Neural Networks also involves defining a number of
hyperparameters that set the configuration of the model. Finding the
appropriate hyperparameter values requires training the model with
different combinations and testing them on the development set. This
hyperparameter tuning is a costly process that needs multiple rounds of
experimentation. However, for this assignments, you will use the
following values:</p>
</div>
<div class="cell code" data-execution_count="8" data-deletable="false"
data-editable="false" id="4TNFrK1KsGcO">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">3</span>  <span class="co"># Number of epochs to train the model</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>train_batch_size <span class="op">=</span> <span class="dv">8</span>  <span class="co"># Number of examples used per gradient update</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">1e-5</span>  <span class="co"># The learning rate for the optimizer</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>max_length <span class="op">=</span> <span class="dv">50</span>  <span class="co"># Maximum lenght of the input sequence</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>output_dir <span class="op">=</span> <span class="st">&quot;modelA&quot;</span>  <span class="co"># The output directory where the model will be written to</span></span></code></pre></div>
</div>
<section id="loading-the-pre-trained-model---1-mark"
class="cell markdown" data-deletable="false" data-editable="false"
id="Z1-gG-57sGcO">
<h2>Loading the Pre-trained Model - [1 Mark]</h2>
<p>The first step you must perform in this assignment is to load the
model and its corresponding tokenizer. <strong>Transformers</strong>
provides support for a wide variety of pre-trained models via specific
classes. However, the library also allows automatically retrieving a
model given jut the name or path using <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/model_doc/auto">AutoClasses</a>.
To fine-tune a pre-trained model for a downstream task, it is necessary
to replace the original top layer of the model with a new specific
output layer. <strong>AutoClasses</strong> also allows you to do this
automatically for various types of Natural Language Processing tasks.
For instance, <code>AutoModelForSequenceClassification</code>
instantiates the model with a top layer for Text Classification.</p>
<p>You must complete the code for the <code>load_model</code> function.
This functions takes the name of the pre-trained model and should load
and return both the model, initialized for Text Classification, and its
corresponding tokenizer. You can get some tips from <a
href="https://huggingface.co/docs/transformers/autoclass_tutorial">Transformers
documentation</a>.</p>
</section>
<div class="cell code" data-execution_count="9" id="_-SjhRrrsGcO">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_model(model_name):   <span class="co"># [1 Mark]</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_name)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(model_name)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, tokenizer</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-deletable="false" data-editable="false" id="WuN58YO8sGcP"
data-outputId="fd002d6d-f590-498a-e9ca-63d33596cdd8">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model_name <span class="op">=</span> <span class="st">&quot;roberta-base&quot;</span> <span class="cf">if</span> base_model <span class="cf">else</span> <span class="st">&quot;roberta-large&quot;</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>model, tokenizer <span class="op">=</span> load_model(model_name)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: 
The secret `HF_TOKEN` does not exist in your Colab secrets.
To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.
You will be able to reuse this secret in all of your notebooks.
Please note that authentication is recommended but still optional to access public models or datasets.
  warnings.warn(
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: [&#39;classifier.dense.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.out_proj.weight&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre>
</div>
</div>
<section id="data-pre-processing---1-mark" class="cell markdown"
data-deletable="false" data-editable="false" id="E3uvPCIMsGcP">
<h2>Data Pre-processing - [1 Mark]</h2>
<p>The <strong>ComVE</strong> dataset consists of 10000 pairs of
statements for the train set, 997 pairs for development and 1000 for
test. Each of the statement pairs is annotated with a <code>0</code> or
<code>1</code> label depending on whether the nonsensical statement is
the first or the second one respectively. The dataset can be loaded into
three <code>DataFrames</code> as follows:</p>
</section>
<div class="cell code" data-execution_count="11" data-deletable="false"
data-editable="false" id="pXocmF6EsGcP">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(data_csv, answers_csv):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pd.read_csv(data_csv)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    reasons <span class="op">=</span> pd.read_csv(answers_csv, header<span class="op">=</span><span class="va">None</span>).rename(columns<span class="op">=</span>{<span class="dv">0</span>: <span class="st">&quot;id&quot;</span>, <span class="dv">1</span>: <span class="st">&quot;label&quot;</span>})</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.merge(data, reasons, on<span class="op">=</span><span class="st">&quot;id&quot;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="12"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:441}"
data-deletable="false" data-editable="false" id="ryomYtYrsGcP"
data-outputId="5e25943d-4812-463f-c1e1-6a23fe33b664">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>train_data_csv <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/Assignment/Week4/ALL data/Training  Data/subtaskA_data_all.csv&quot;</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>train_answers_csv <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/Assignment/Week4/ALL data/Training  Data/subtaskA_answers_all.csv&quot;</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>train_data <span class="op">=</span> load_data(train_data_csv, train_answers_csv)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>dev_data_csv <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/Assignment/Week4/ALL data/Dev Data/subtaskA_dev_data.csv&quot;</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>dev_answers_csv <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/Assignment/Week4/ALL data/Dev Data/subtaskA_gold_answers.csv&quot;</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>dev_data <span class="op">=</span> load_data(dev_data_csv, dev_answers_csv)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>test_data_csv <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/Assignment/Week4/ALL data/Test Data/subtaskA_test_data.csv&quot;</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>test_answers_csv <span class="op">=</span> <span class="st">&quot;/content/drive/MyDrive/Assignment/Week4/ALL data/Test Data/subtaskA_gold_answers.csv&quot;</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> load_data(test_data_csv, test_answers_csv)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> shrink_dataset:</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    train_data <span class="op">=</span> train_data.sample(n<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>    dev_data <span class="op">=</span> dev_data.sample(n<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    test_data <span class="op">=</span> test_data.sample(n<span class="op">=</span><span class="dv">100</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>train_data</span></code></pre></div>
<div class="output execute_result" data-execution_count="12">

  <div id="df-b9cc7761-5510-4232-a90a-4f4ccb46c44b" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sent0</th>
      <th>sent1</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6252</th>
      <td>6252</td>
      <td>a duck walks on three legs</td>
      <td>a duck walks on two legs</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4684</th>
      <td>4684</td>
      <td>Jack's mom praised him because he broke the plate</td>
      <td>Jack's mom condemned him because he broke the ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1731</th>
      <td>1731</td>
      <td>People use electricity to buy things</td>
      <td>People use money to buy things</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4742</th>
      <td>4742</td>
      <td>The speaker is damaged, thus I can't hear anyt...</td>
      <td>The display is damaged, thus I can't hear anyt...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4521</th>
      <td>4521</td>
      <td>Santa Claus is the legend of the East</td>
      <td>Santa Claus is the legend of the West</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>3787</th>
      <td>3787</td>
      <td>If you want to visit a museum then you should ...</td>
      <td>If you want to visit a museum then you should ...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9189</th>
      <td>9189</td>
      <td>the mirror in the bathroom fogged up after she...</td>
      <td>the mirror in the bathroom fogged up after she...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7825</th>
      <td>7825</td>
      <td>My mother keeps a tiger and takes care of it a...</td>
      <td>My mother keeps a cat and takes care of it as ...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7539</th>
      <td>7539</td>
      <td>His lens cover is broken, so he can not use it...</td>
      <td>His lens is broken, so he can not use it to ta...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7231</th>
      <td>7231</td>
      <td>I'm chatting with my friends.</td>
      <td>I'm chatting with animals.</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>100 rows Ã— 4 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-b9cc7761-5510-4232-a90a-4f4ccb46c44b')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-b9cc7761-5510-4232-a90a-4f4ccb46c44b button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-b9cc7761-5510-4232-a90a-4f4ccb46c44b');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-ab9d06fd-8e7a-4767-af92-f31ac0dff67c">
  <button class="colab-df-quickchart" onclick="quickchart('df-ab9d06fd-8e7a-4767-af92-f31ac0dff67c')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-ab9d06fd-8e7a-4767-af92-f31ac0dff67c button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_b9b58026-583e-4caa-8f92-df576c462b82">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('train_data')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_b9b58026-583e-4caa-8f92-df576c462b82 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('train_data');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="Gwwvy-zrsGcP">
<p><a href="https://huggingface.co/docs/datasets/index">Datasets</a> is
a library for dataset management that provides a set of tools to
manipulate data in a easy and efficient way. Since it is fully
integrated with <strong>Transformers</strong>, it is very convenient to
use both libraries together. <strong>Datasets</strong> allows accessing
and sharing datasets through the <a
href="https://huggingface.co/datasets">Hugging Face Hub</a>. The core
component of this library is the <a
href="https://huggingface.co/docs/datasets/v2.10.0/en/package_reference/main_classes#datasets.Dataset">Dataset</a>
class that implements an <a
href="https://arrow.apache.org/docs/python/generated/pyarrow.Table.html">Apache
Arrow table</a>. Similar to a <strong>pandas</strong>
<code>DataFrame</code>, a <code>Dataset</code> object stores a table
where each row corresponds to an example of the dataset and each column
contains a different type of data. There are different ways to load the
data into a <code>Dataset</code>, for example, from a
<code>Dataframe</code>:</p>
</div>
<div class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-deletable="false" data-editable="false" id="vmn6kOKjsGcQ"
data-outputId="31e0febb-3b58-4b59-98a7-9af1e9bc87d2">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> Dataset.from_pandas(train_data)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>dev_dataset <span class="op">=</span> Dataset.from_pandas(dev_data)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> Dataset.from_pandas(test_data)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>train_dataset[<span class="dv">0</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="13">
<pre><code>{&#39;id&#39;: 6252,
 &#39;sent0&#39;: &#39;a duck walks on three legs&#39;,
 &#39;sent1&#39;: &#39;a duck walks on two legs&#39;,
 &#39;label&#39;: 0,
 &#39;__index_level_0__&#39;: 6252}</code></pre>
</div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="PRoP9ZQMsGcQ">
<p>One of the most powerful <strong>Datasets</strong> tools is the <a
href="https://huggingface.co/docs/datasets/v2.10.0/en/nlp_process#map">map</a>
function which allows pre-processing the dataset in batches. The
function takes another callable as argument and applies it to every row
in the <code>Dataset</code>. The goal of the next exercise is to
implement a function to tokenize the statement pairs that will be used
as a parameter of the <code>map</code> function.</p>
<p>You must complete the code for the <code>preprocess_data</code>
function. This function takes a batch of examples from a
<code>Dataset</code>, the tokenizer returned by <code>load_model</code>
and the <code>max_length</code> hyperparameter. The function must run
the tokenizer jointly on the <code>sent0</code> and <code>sent1</code>
columns of the <code>Dataset</code>. The tokenizer must pad and truncate
the sequences to the <code>max_length</code> value. You can use the <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/preprocessing">Preprocessing</a>
and the <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/tokenizer">Tokenizer</a>
documentation as reference. The <code>preprocess_data</code> should
return the output of the tokenizer.</p>
<p>The <code>tokenizer</code> should return a <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/tokenizer#transformers.BatchEncoding">BatchEncoding</a>
object with two fields for each data example:</p>
<ul>
<li><em>input_ids</em>: A list of token indices that will be used as the
input of the model.</li>
<li><em>attention_mask</em>: A list of indices masking out which tokens
the model should not attend to.</li>
</ul>
<p>The <code>map</code> function takes these fields and inserts them
into the <code>Dataset</code> as new two columns. For example, the
result for the first row in the <code>Dataset</code> should look
like:</p>
<blockquote>
<pre>
{'id': 6252, 'sent0': 'a duck walks on three legs', 'sent1': 'a duck walks on two legs', 'label': 0, '__index_level_0__': 6252, 'input_ids': [0, 102, 15223, 5792, 15, 130, 5856, 2, 2, 102, 15223, 5792, 15, 80, 5856, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
</pre>
</blockquote>
<p>Each value in <code>input_ids</code> represents a sub-word of the
<code>tokenizer</code> vocabulary. For the example above,
<code>input_ids</code> corresponds to the following sequence of
sub-words:</p>
<blockquote>
<pre>
['&lt;s&gt;', 'a', 'Ä duck', 'Ä walks', 'Ä on', 'Ä three', 'Ä legs', '&lt;/s&gt;', '&lt;/s&gt;', 'a', 'Ä duck', 'Ä walks', 'Ä on', 'Ä two', 'Ä legs', '&lt;/s&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;', '&lt;pad&gt;']
</pre>
</blockquote>
<p>Notice that the <strong>Hugging Face</strong> implementation of
<strong>RoBERTa</strong>'s tokenizer uses the <code>&lt;s&gt;</code>
token equivalently to <strong>BERT</strong>'s <code>[CLS]</code> token
and the <code>&lt;/s&gt;</code> token to mark both the end and the
separation of the sentences. The <code>Ä </code> character indicates when
there is a blank space before the token in the original text. This helps
to know which tokens are the first sub-words of the words.</p>
</div>
<div class="cell code" data-execution_count="14" id="8sWzsmw3sGcQ">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_data(examples, tokenizer, max_length):   <span class="co"># [1 Mark]</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    tokenized_inputs <span class="op">=</span> tokenizer(examples[<span class="st">&quot;sent0&quot;</span>], examples[<span class="st">&quot;sent1&quot;</span>], padding<span class="op">=</span><span class="st">&#39;max_length&#39;</span>, truncation<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span>max_length)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>    examples[<span class="st">&quot;input_ids&quot;</span>] <span class="op">=</span> tokenized_inputs[<span class="st">&quot;input_ids&quot;</span>]</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    examples[<span class="st">&quot;attention_mask&quot;</span>] <span class="op">=</span> tokenized_inputs[<span class="st">&quot;attention_mask&quot;</span>]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> examples</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:168,&quot;referenced_widgets&quot;:[&quot;306b7a98222d4b708828dae3425dc1d3&quot;,&quot;6d1321c0507647d49fb9f1adff25246a&quot;,&quot;d35070dce82f4970b4c2fddefb6c441f&quot;,&quot;497811d05af346429cb3e8bf60b690b8&quot;,&quot;917c60d03d214058881568aa9e11717a&quot;,&quot;8eea25e1853e45f5b71299634c9a3927&quot;,&quot;50655825ac8045a0baee77814270cc4d&quot;,&quot;d9b7170c3e42416e8db0ff4899c5028a&quot;,&quot;a433b799633b43f4969f031d4ae1d2e5&quot;,&quot;94b01b40b3244e46a2456e0096328645&quot;,&quot;4c5d10b93f704ab1863cbddfbb438c0e&quot;,&quot;fdd0d09549664d9fa7741913c7764894&quot;,&quot;957b2045acbc441abe4834f32e7cde6e&quot;,&quot;c6d7be061d6340168d9a763e3e66c257&quot;,&quot;946fc75df7a74f9d870af2f22297f1f8&quot;,&quot;bc23968ef10344feab36563b06cfc7e0&quot;,&quot;624460a160844e48b8ee2bde7ef7c9e5&quot;,&quot;a7adc7dd885a4b94997fbac00455ef60&quot;,&quot;81f4b8582473484b987fc30c9b268672&quot;,&quot;0b8985989e174d1cbd24370309d4f38c&quot;,&quot;d07a15c0c5c74b5f880afe1226f167e1&quot;,&quot;d2ed2fd696bd46e1a156a792e8863ace&quot;,&quot;48d7171a452d479986111580f3074a8e&quot;,&quot;d38e1201254a4ad385408b21f41ac71b&quot;,&quot;92a625dab7a24484963d4c1a16c4b6a6&quot;,&quot;5e4d5b5f36a1463dbd2a260622318782&quot;,&quot;e875021e6b0c410290797798f27a192f&quot;,&quot;59a1dfdd3507411992a2ae940971e846&quot;,&quot;fa393a5270c34b06af430b698b2212b4&quot;,&quot;d57e92904204400d8534786f8873b781&quot;,&quot;d7bfaf6b04a546e8a47f068a81da0e5f&quot;,&quot;c9cbcfd2068646fca31209269aee2f6c&quot;,&quot;7670dfdfc76c449ca241e0df289099ca&quot;]}"
data-deletable="false" data-editable="false" id="axe_WV-3sGcQ"
data-outputId="b5e6fe4e-8b9d-412a-dc87-571767233d4e">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> train_dataset.<span class="bu">map</span>(<span class="kw">lambda</span> x: preprocess_data(x, tokenizer, max_length), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>dev_dataset <span class="op">=</span> dev_dataset.<span class="bu">map</span>(<span class="kw">lambda</span> x: preprocess_data(x, tokenizer, max_length), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> test_dataset.<span class="bu">map</span>(<span class="kw">lambda</span> x: preprocess_data(x, tokenizer, max_length), batched<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_dataset[<span class="dv">0</span>])</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tokenizer.convert_ids_to_tokens(train_dataset[<span class="dv">0</span>][<span class="st">&quot;input_ids&quot;</span>]))</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb21"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;306b7a98222d4b708828dae3425dc1d3&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb22"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fdd0d09549664d9fa7741913c7764894&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb23"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;48d7171a452d479986111580f3074a8e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>{&#39;id&#39;: 6252, &#39;sent0&#39;: &#39;a duck walks on three legs&#39;, &#39;sent1&#39;: &#39;a duck walks on two legs&#39;, &#39;label&#39;: 0, &#39;__index_level_0__&#39;: 6252, &#39;input_ids&#39;: [0, 102, 15223, 5792, 15, 130, 5856, 2, 2, 102, 15223, 5792, 15, 80, 5856, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
[&#39;&lt;s&gt;&#39;, &#39;a&#39;, &#39;Ä duck&#39;, &#39;Ä walks&#39;, &#39;Ä on&#39;, &#39;Ä three&#39;, &#39;Ä legs&#39;, &#39;&lt;/s&gt;&#39;, &#39;&lt;/s&gt;&#39;, &#39;a&#39;, &#39;Ä duck&#39;, &#39;Ä walks&#39;, &#39;Ä on&#39;, &#39;Ä two&#39;, &#39;Ä legs&#39;, &#39;&lt;/s&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;, &#39;&lt;pad&gt;&#39;]
</code></pre>
</div>
</div>
<section id="fine-tuning---4-marks" class="cell markdown"
data-deletable="false" data-editable="false" id="FNew8OqEsGcR">
<h2>Fine-tuning - [4 Marks]</h2>
<p>Although it is possible to write customized training loops for the
<strong>Transormers</strong> models using <strong>keras</strong> or
<strong>pytorch</strong>, <strong>Transformers</strong> provides a <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/trainer">Trainer</a>
API that allows fine-tuning efficiently with a few simple steps. The
training is highly customizable through a wide range of options and
hyperparameters that are handled by the <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>
class. Your next goal is to create both the
<code>TrainingArguments</code> and <code>Trainer</code> objects that
will be used to fine-tune <strong>RoBERTa</strong>. See the <a
href="https://huggingface.co/docs/transformers/training">documentation</a>
for an introduction on how to perform these steps.</p>
<p>You must complete the code for the
<code>create_training_arguments</code> function. This function takes as
arguments the <code>epochs</code>, <code>train_batch_size</code> and
<code>learning_rate</code> hyperparameters along with the
<code>output_dir</code>. The function should use these arguments to
create and return a <code>TrainingArguments</code> object. During the
training, the model must be evaluated on the development test after
every epoch. <code>TrainingArguments</code> should include this
strategy.</p>
<blockquote>
<p><strong>Important!</strong> By default, <code>Trainer</code> saves a
checkpoint of the model every 500 training steps. For this assignment,
avoid this behavior by setting <code>save_strategy="no"</code> when
creating the <code>TrainingArguments</code>.</p>
</blockquote>
</section>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="sMzAaIqv1bE5" data-outputId="867710ca-3f18-4aeb-e53f-e7842e73e91b">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install transformers[torch]</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.41.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.15.4)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.23.4)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.1)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2024.5.15)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.32.3)
Requirement already satisfied: tokenizers&lt;0.20,&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)
Requirement already satisfied: safetensors&gt;=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.4)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.0+cu121)
Requirement already satisfied: accelerate&gt;=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.31.0)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.21.0-&gt;transformers[torch]) (5.9.5)
Requirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.23.0-&gt;transformers[torch]) (2023.6.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.23.0-&gt;transformers[torch]) (4.12.2)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (1.12.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (3.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (3.1.4)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (12.1.105)
Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;transformers[torch]) (2.3.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch-&gt;transformers[torch]) (12.5.82)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers[torch]) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers[torch]) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers[torch]) (2.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers[torch]) (2024.6.2)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch-&gt;transformers[torch]) (2.1.5)
Requirement already satisfied: mpmath&lt;1.4.0,&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;transformers[torch]) (1.3.0)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5fvh8sYH3AU7" data-outputId="0d571721-2b7f-499d-d7de-f186941b9111">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install accelerate <span class="op">-</span>U</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)
Requirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)
Requirement already satisfied: torch&gt;=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)
Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.4)
Requirement already satisfied: safetensors&gt;=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.15.4)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (4.12.2)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (1.12.1)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (3.1.4)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (2023.6.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (2.20.5)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (12.1.105)
Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch&gt;=1.10.0-&gt;accelerate) (2.3.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch&gt;=1.10.0-&gt;accelerate) (12.5.82)
Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;accelerate) (2.32.3)
Requirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub-&gt;accelerate) (4.66.4)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&gt;=1.10.0-&gt;accelerate) (2.1.5)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;accelerate) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;accelerate) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;accelerate) (2.0.7)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub-&gt;accelerate) (2024.6.2)
Requirement already satisfied: mpmath&lt;1.4.0,&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch&gt;=1.10.0-&gt;accelerate) (1.3.0)
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="18" id="nBIHIRNOsGcR">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_training_arguments(epochs, train_batch_size, learning_rate, output_dir):    <span class="co"># [1 Mark]</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    training_args <span class="op">=</span> TrainingArguments(</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>        output_dir<span class="op">=</span>output_dir,</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>        num_train_epochs<span class="op">=</span>epochs,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>        per_device_train_batch_size<span class="op">=</span>train_batch_size,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>        save_strategy<span class="op">=</span><span class="st">&quot;no&quot;</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>        eval_strategy<span class="op">=</span><span class="st">&quot;epoch&quot;</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>        logging_dir<span class="op">=</span>output_dir,</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>        logging_steps<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>        learning_rate<span class="op">=</span>learning_rate,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>        report_to<span class="op">=</span><span class="st">&quot;none&quot;</span>,</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> training_args</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="20" data-deletable="false"
data-editable="false" id="gz2up_EEsGcR">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>train_args <span class="op">=</span> create_training_arguments(epochs, train_batch_size, learning_rate, output_dir)</span></code></pre></div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="GbctDQQssGcR">
<p>Next, you will create a <code>Trainer</code> object with the training
arguments.</p>
<p>You must complete the code for the <code>create_trainer</code>
function. The function takes as input the model returned by the
<code>load_model</code>, the <code>TrainingArguments</code> created by
<code>create_training_arguments</code> and the train and development
<code>Datasets</code>. The <code>create_trainer</code> function must
create and return a <code>Trainer</code> object with the model and the
training arguments. The <code>Trainer</code> must be set up so that the
train <code>Dataset</code> is used for training and the development
<code>Dataset</code> is used to evaluate the model during the
training.</p>
</div>
<div class="cell code" data-execution_count="21" id="nCn53fuwsGcR">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_trainer(model, train_args, train_dataset, dev_dataset):    <span class="co"># [1 Mark]</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    trainer <span class="op">=</span> Trainer(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>        args<span class="op">=</span>train_args,</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>        train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>        eval_dataset<span class="op">=</span>dev_dataset,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> trainer</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="22" data-deletable="false"
data-editable="false" id="haf52HmFsGcR">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>trainer <span class="op">=</span> create_trainer(model, train_args, train_dataset, dev_dataset)</span></code></pre></div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="DcMQcGOHsGcR">
<p>The <code>trainer</code> object created by
<code>create_trainer</code> is ready to fine-tune the model by just
running:</p>
</div>
<div class="cell code" data-execution_count="23"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:222}"
data-deletable="false" data-editable="false" id="tMBY-KGfsGcS"
data-outputId="1d30664d-9b13-41c2-b501-926843737fa0">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>trainer.train()</span></code></pre></div>
<div class="output display_data">

    <div>
      
      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [39/39 04:35, Epoch 3/3]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>No log</td>
      <td>0.692062</td>
    </tr>
    <tr>
      <td>2</td>
      <td>No log</td>
      <td>0.691658</td>
    </tr>
    <tr>
      <td>3</td>
      <td>No log</td>
      <td>0.691565</td>
    </tr>
  </tbody>
</table><p>
</div>
<div class="output execute_result" data-execution_count="23">
<pre><code>TrainOutput(global_step=39, training_loss=0.6857539934989734, metrics={&#39;train_runtime&#39;: 283.7727, &#39;train_samples_per_second&#39;: 1.057, &#39;train_steps_per_second&#39;: 0.137, &#39;total_flos&#39;: 7708331700000.0, &#39;train_loss&#39;: 0.6857539934989734, &#39;epoch&#39;: 3.0})</code></pre>
</div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="NYh4FmIssGcS">
<p>After training, the model can be used to make predictions on
unlabeled data using the <a
href="https://huggingface.co/docs/transformers/v4.27.2/en/main_classes/trainer#transformers.Trainer.predict">predict</a>
method of the <code>Trainer</code> class.</p>
<p>You must complete the code for the <code>make_predictions</code>
function. The function takes as input the <code>Trainer</code> object
and test <code>Dataset</code>. The function must run the
<code>predict</code> method on the input data. The <code>predict</code>
method will return a <code>NamedTuple</code> including a
<strong>numpy</strong> array with the predictions. For each statement
pair in the input, the array should contain a vector with the logits
(the values used as input of the softmax) predicted for every label. The
output of <code>make_predictions</code> must include only the index of
the label with the highest logit value. For example, if the prediction
for one statement pair is <code>[0.10053499, -0.01917896]</code>, the
output for that example should be <code>0</code>. For this, you can
apply the <a
href="https://numpy.org/doc/stable/reference/generated/numpy.argmax.html">argmax</a>
method along the last axis of the <strong>numpy</strong> array.</p>
</div>
<div class="cell code" data-execution_count="25" id="NN2KdWsd8uVc">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co">#importing numpy library</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="26" id="j9ceKAczsGcS">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_predictions(trainer, test_dataset):    <span class="co"># [2 Marks]</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> trainer.predict(test_dataset)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    predicted_labels <span class="op">=</span> np.argmax(predictions.predictions, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> predicted_labels</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="27"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:458}"
data-deletable="false" data-editable="false" id="1KlFtr7ZsGcS"
data-outputId="43a7f90d-0d19-4ffb-c23f-2778da1a08dd">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> make_predictions(trainer, test_dataset)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>test_data[<span class="st">&quot;prediction&quot;</span>] <span class="op">=</span> predictions</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>test_data</span></code></pre></div>
<div class="output display_data">

</div>
<div class="output execute_result" data-execution_count="27">

  <div id="df-050a1878-ba2a-4be7-89f8-2aede6398c07" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>sent0</th>
      <th>sent1</th>
      <th>label</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>521</th>
      <td>324</td>
      <td>She put the papers into the filing cabinet.</td>
      <td>She put the filing cabinet into the papers.</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>737</th>
      <td>1455</td>
      <td>The cat used the litter box</td>
      <td>The lion used the litter box</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>740</th>
      <td>13</td>
      <td>Cigarette is good for healthy</td>
      <td>Cereal is good for healthy</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>660</th>
      <td>207</td>
      <td>Pens are for writing</td>
      <td>Pens are for painting</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>411</th>
      <td>774</td>
      <td>he put a piece of plastic on the bread</td>
      <td>he put a piece of cheese on the bread</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>436</th>
      <td>225</td>
      <td>Carol turned on the potato</td>
      <td>Carol turned on the flashlight</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>764</th>
      <td>1663</td>
      <td>i use my dog to play cricket</td>
      <td>i use the bat to play cricket</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>88</th>
      <td>82</td>
      <td>Dolphins are fish.</td>
      <td>Dolphins are mammals.</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>63</th>
      <td>800</td>
      <td>the family adopted a dinosaur to be their new pet</td>
      <td>the family adopted a dog to be their new pet</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>826</th>
      <td>948</td>
      <td>he learned with his refrigerator before the exam</td>
      <td>he learned with his textbooks before the exam</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>100 rows Ã— 5 columns</p>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-050a1878-ba2a-4be7-89f8-2aede6398c07')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-050a1878-ba2a-4be7-89f8-2aede6398c07 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-050a1878-ba2a-4be7-89f8-2aede6398c07');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-0c39e3b1-3522-4a73-8e29-06f294723f36">
  <button class="colab-df-quickchart" onclick="quickchart('df-0c39e3b1-3522-4a73-8e29-06f294723f36')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-0c39e3b1-3522-4a73-8e29-06f294723f36 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_8ece05f6-eff3-4afa-beaa-69537ebf35f9">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('test_data')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_8ece05f6-eff3-4afa-beaa-69537ebf35f9 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('test_data');
      }
      })();
    </script>
  </div>

    </div>
  </div>

</div>
</div>
<div class="cell markdown" data-deletable="false" data-editable="false"
id="eCJg0DU8sGcS">
<p>The <strong>Subtasks A</strong> of <strong>ComVE</strong> is
evaluated using accuracy. The <a
href="https://huggingface.co/docs/evaluate/index">evaluate</a> library
provides support to apply this and other metrics. The
<code>evaluate_prediction</code> function takes the test
<code>DataFrame</code> and calculates the accuracy comparing the
<code>prediction</code> and <code>label</code> columns. With
<code>shrink_dataset</code> and <code>base_model</code> set to
<code>True</code> the model is not able to learn the task so the
expected score is only <em>0.49</em>. With a full training run, i.e.
with <code>shrink_dataset</code> and <code>base_model</code> set to
<code>False</code>, the score should be around <em>0.929</em>.</p>
</div>
<div class="cell code" data-execution_count="28"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:66,&quot;referenced_widgets&quot;:[&quot;5620bfb15a9b4b278ce9845a6e850a34&quot;,&quot;1985321e94d148c689b9625a33ca2849&quot;,&quot;d22cf2fff2c24a74ad1814e6e3cb0595&quot;,&quot;ec4ff7deb9814559b9c30fb1e7a0c178&quot;,&quot;65285e66954a4d0dbdf58595a28dd1f8&quot;,&quot;8fec5ffad3fd4f9385ccf95ac4fb308c&quot;,&quot;a0a352ddb5144ff4aaef9a816a4ae969&quot;,&quot;fb8aba051d5b433a8e0ac86cfab8a82f&quot;,&quot;1ecffd73d66e4cdabd154bda9309dcc5&quot;,&quot;02de11a4fbe24f50b4f6382eaa5b6992&quot;,&quot;96ab3c3e06cc4461a07eb5212003b356&quot;]}"
data-deletable="false" data-editable="false" id="OpWONmc1sGcS"
data-outputId="02374fb4-6377-4d05-c86c-53cee2a58599">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_prediction(test_data):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    accuracy <span class="op">=</span> evaluate.load(<span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> accuracy.compute(predictions<span class="op">=</span>test_data[<span class="st">&quot;prediction&quot;</span>].values, references<span class="op">=</span>test_data[<span class="st">&quot;label&quot;</span>].values)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>evaluate_prediction(test_data)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb39"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5620bfb15a9b4b278ce9845a6e850a34&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output execute_result" data-execution_count="28">
<pre><code>{&#39;accuracy&#39;: 0.49}</code></pre>
</div>
</div>
<div class="cell code" id="-eoo3qLN9GTn">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
